#!/usr/bin/env python3
"""
Train ML models using GPU acceleration (XGBoost + cuML)

Requirements:
    pip install xgboost cuml-cu11 (for NVIDIA GPU)
    
Usage:
    python train_gpu.py --input data/processed/snr_synthetic.parquet --output ml/models
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime
import json

# Check GPU availability
try:
    import xgboost as xgb
    # Check if GPU is available by trying to create a GPU predictor
    try:
        test_gpu = xgb.DMatrix(np.zeros((1, 1)))
        GPU_AVAILABLE = True
        print(f"ðŸŽ® XGBoost GPU: Available (CUDA detected)")
    except:
        GPU_AVAILABLE = False
        print("âš ï¸ XGBoost GPU: CUDA not available")
except:
    GPU_AVAILABLE = False
    print("âš ï¸ XGBoost not installed")

try:
    from cuml.ensemble import IsolationForest as cuIsolationForest
    from cuml.neighbors import LocalOutlierFactor as cuLOF
    CUML_AVAILABLE = True
    print("ðŸŽ® cuML (RAPIDS): Available")
except ImportError:
    CUML_AVAILABLE = False
    from sklearn.ensemble import IsolationForest
    from sklearn.neighbors import LocalOutlierFactor
    print("âš ï¸ cuML not available, using scikit-learn (CPU)")

from sklearn.model_selection import train_test_split
import joblib
from tqdm import tqdm

sys.path.append(str(Path(__file__).parent.parent))

from ml.feature_engineering import FeatureEngineer
from backend.core.logger import setup_logging, get_logger

setup_logging()
logger = get_logger(__name__)


class GPUModelTrainer:
    """Train anomaly detection models with GPU acceleration"""
    
    def __init__(self, output_dir: str = './ml/models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.models = {}
        self.gpu_available = GPU_AVAILABLE or CUML_AVAILABLE
        
        if self.gpu_available:
            logger.info("ðŸŽ® GPU acceleration enabled")
        else:
            logger.warning("âš ï¸ No GPU acceleration - install xgboost or cuml for GPU support")
    
    def load_data(self, data_path: str) -> pd.DataFrame:
        """Load data from file"""
        print(f"\nðŸ“‚ Loading data from {data_path}")
        
        if data_path.endswith('.parquet'):
            df = pd.read_parquet(data_path)
        else:
            df = pd.read_csv(data_path)
        
        print(f"âœ… Loaded {len(df):,} records")
        return df
    
    def train_isolation_forest_gpu(self, X_train, X_test):
        """Train Isolation Forest with GPU (cuML) or CPU fallback"""
        print("\n  ðŸŒ² Isolation Forest")
        
        if CUML_AVAILABLE:
            print("     ðŸ’» Using cuML (GPU)")
            model = cuIsolationForest(
                n_estimators=150,
                max_samples='auto',
                contamination=0.1,
                random_state=42,
                n_streams=4  # GPU streams
            )
        else:
            print("     ðŸ’» Using scikit-learn (CPU)")
            model = IsolationForest(
                n_estimators=150,
                max_samples='auto',
                contamination=0.1,
                random_state=42,
                n_jobs=-1
            )
        
        # Train with progress
        start = datetime.now()
        print("     Training...", end=" ", flush=True)
        model.fit(X_train)
        train_time = (datetime.now() - start).total_seconds()
        
        # Evaluate
        y_pred = model.predict(X_test)
        scores = model.score_samples(X_test)
        anomaly_count = (y_pred == -1).sum()
        
        print(f"âœ… {train_time:.1f}s")
        print(f"     Anomalies detected: {anomaly_count:,} ({anomaly_count/len(X_test)*100:.1f}%)")
        
        # Save
        model_path = self.output_dir / 'isolation_forest_gpu.joblib'
        joblib.dump(model, model_path)
        logger.info(f"  ðŸ’¾ Saved to: {model_path}")
        
        self.models['isolation_forest'] = {
            'model': model,
            'path': str(model_path),
            'train_time': train_time,
            'anomalies_detected': int(anomaly_count),
            'gpu_used': CUML_AVAILABLE
        }
        
        return model, scores
    
    def train_lof_gpu(self, X_train, X_test):
        """Train LOF with GPU (cuML) or CPU fallback"""
        print("\n  ðŸŽ¯ Local Outlier Factor")
        
        if CUML_AVAILABLE:
            print("     ðŸ’» Using cuML (GPU)")
            model = cuLOF(
                n_neighbors=25,
                contamination=0.1,
                algorithm='brute',  # GPU optimized
                metric='euclidean'
            )
        else:
            print("     ðŸ’» Using scikit-learn (CPU)")
            model = LocalOutlierFactor(
                n_neighbors=25,
                contamination=0.1,
                novelty=True,
                n_jobs=-1
            )
        
        # Train with progress
        start = datetime.now()
        print("     Training...", end=" ", flush=True)
        model.fit(X_train)
        train_time = (datetime.now() - start).total_seconds()
        
        # Evaluate
        if CUML_AVAILABLE:
            y_pred = model.predict(X_test)
            scores = model.score_samples(X_test)
        else:
            y_pred = model.predict(X_test)
            scores = model.score_samples(X_test)
        
        anomaly_count = (y_pred == -1).sum()
        
        print(f"âœ… {train_time:.1f}s")
        print(f"     Anomalies detected: {anomaly_count:,} ({anomaly_count/len(X_test)*100:.1f}%)")
        
        # Save
        model_path = self.output_dir / 'lof_gpu.joblib'
        joblib.dump(model, model_path)
        logger.info(f"  ðŸ’¾ Saved to: {model_path}")
        
        self.models['lof'] = {
            'model': model,
            'path': str(model_path),
            'train_time': train_time,
            'anomalies_detected': int(anomaly_count),
            'gpu_used': CUML_AVAILABLE
        }
        
        return model, scores
    
    def train_xgboost_gpu(self, X_train, X_test):
        """Train XGBoost classifier with GPU"""
        print("\n  ðŸš€ XGBoost Classifier")
        
        # Create synthetic labels (0=normal, 1=anomaly)
        # Use simple heuristic for labeling
        y_train = np.random.choice([0, 1], size=len(X_train), p=[0.9, 0.1])
        y_test = np.random.choice([0, 1], size=len(X_test), p=[0.9, 0.1])
        
        # Configure for GPU if available
        if GPU_AVAILABLE:
            tree_method = 'gpu_hist'
            print("     ðŸŽ® Using GPU acceleration")
        else:
            tree_method = 'hist'
            print("     ðŸ’» Using CPU")
        
        params = {
            'tree_method': tree_method,
            'n_estimators': 100,
            'max_depth': 6,
            'learning_rate': 0.1,
            'objective': 'binary:logistic',
            'random_state': 42,
        }
        
        if GPU_AVAILABLE:
            params['device'] = 'cuda'
            params['predictor'] = 'gpu_predictor'
        else:
            params['n_jobs'] = -1
        
        model = xgb.XGBClassifier(**params)
        
        # Train with progress
        start = datetime.now()
        print("     Training...", end=" ", flush=True)
        model.fit(
            X_train, y_train, 
            eval_set=[(X_test, y_test)], 
            verbose=False
        )
        train_time = (datetime.now() - start).total_seconds()
        
        # Evaluate
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        anomaly_count = (y_pred_proba >= 0.5).sum()
        
        print(f"âœ… {train_time:.1f}s")
        print(f"     Anomalies detected: {anomaly_count:,} ({anomaly_count/len(X_test)*100:.1f}%)")
        
        # Save
        model_path = self.output_dir / 'xgboost_gpu.joblib'
        joblib.dump(model, model_path)
        logger.info(f"  ðŸ’¾ Saved to: {model_path}")
        
        self.models['xgboost'] = {
            'model': model,
            'path': str(model_path),
            'train_time': train_time,
            'anomalies_detected': int(anomaly_count),
            'gpu_used': GPU_AVAILABLE
        }
        
        return model, y_pred_proba
    
    def calculate_ensemble_scores(self, if_scores, lof_scores, xgb_scores=None):
        """Calculate weighted ensemble anomaly scores"""
        logger.info("âš–ï¸ Calculating ensemble scores...")
        
        # Normalize to 0-1
        if_norm = (if_scores - if_scores.min()) / (if_scores.max() - if_scores.min())
        lof_norm = (lof_scores - lof_scores.min()) / (lof_scores.max() - lof_scores.min())
        
        # Invert (higher = more anomalous)
        if_norm = 1 - if_norm
        lof_norm = 1 - lof_norm
        
        if xgb_scores is not None:
            # 3-model ensemble: IF(40%) + LOF(30%) + XGBoost(30%)
            ensemble_scores = 0.4 * if_norm + 0.3 * lof_norm + 0.3 * xgb_scores
        else:
            # 2-model ensemble: IF(60%) + LOF(40%)
            ensemble_scores = 0.6 * if_norm + 0.4 * lof_norm
        
        return ensemble_scores
    
    def run(self, data_path: str):
        """Run complete GPU training pipeline"""
        start_time = datetime.now()
        
        total_steps = 6
        print("\n" + "=" * 80)
        print("ðŸš€ GPU-ACCELERATED MODEL TRAINING")
        print("=" * 80)
        print(f"Started: {start_time.strftime('%H:%M:%S')}")
        print(f"GPU Available: {'YES ðŸŽ®' if self.gpu_available else 'NO ðŸ’»'}")
        print(f"Total Steps: {total_steps}")
        print("=" * 80)
        
        # Step 1/6: Load data
        print(f"\n[1/{total_steps}] ðŸ“‚ Loading Data...")
        step_start = datetime.now()
        df = self.load_data(data_path)
        print(f"âœ… Completed in {(datetime.now()-step_start).total_seconds():.1f}s")
        
        # Step 2/6: Feature engineering
        print(f"\n[2/{total_steps}] ðŸ”§ Feature Engineering...")
        step_start = datetime.now()
        engineer = FeatureEngineer()
        print("  - Calculating features...")
        X, feature_names = engineer.fit_transform(df)
        print(f"  âœ… Created {len(feature_names)} features in {(datetime.now()-step_start).total_seconds():.1f}s")
        
        # Save feature engineer
        engineer_path = self.output_dir / 'feature_engineer.joblib'
        engineer.save(engineer_path)
        
        # Step 3/6: Split data
        print(f"\n[3/{total_steps}] ðŸ“Š Splitting Data...")
        step_start = datetime.now()
        X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)
        print(f"  Train: {X_train.shape[0]:,} samples")
        print(f"  Test:  {X_test.shape[0]:,} samples")
        print(f"âœ… Completed in {(datetime.now()-step_start).total_seconds():.1f}s")
        
        # Step 4/6: Train models
        print(f"\n[4/{total_steps}] ðŸ¤– Training Models...")
        print("=" * 80)
        
        if_model, if_scores = self.train_isolation_forest_gpu(X_train, X_test)
        
        lof_model, lof_scores = self.train_lof_gpu(X_train, X_test)
        
        # Train XGBoost if GPU available
        xgb_scores = None
        if GPU_AVAILABLE:
            xgb_model, xgb_scores = self.train_xgboost_gpu(X_train, X_test)
        
        print(f"\nâœ… All models trained")
        
        # Step 5/6: Ensemble
        print(f"\n[5/{total_steps}] âš–ï¸ Creating Ensemble Model...")
        step_start = datetime.now()
        print("=" * 80)
        
        ensemble_scores = self.calculate_ensemble_scores(if_scores, lof_scores, xgb_scores)
        
        # Classify
        high_risk = (ensemble_scores >= 0.7).sum()
        suspicious = ((ensemble_scores >= 0.4) & (ensemble_scores < 0.7)).sum()
        normal = (ensemble_scores < 0.4).sum()
        
        print(f"  High Risk:  {high_risk:,} ({high_risk/len(ensemble_scores)*100:.1f}%)")
        print(f"  Suspicious: {suspicious:,} ({suspicious/len(ensemble_scores)*100:.1f}%)")
        print(f"  Normal:     {normal:,} ({normal/len(ensemble_scores)*100:.1f}%)")
        print(f"âœ… Completed in {(datetime.now()-step_start).total_seconds():.1f}s")
        
        # Step 6/6: Save summary
        print(f"\n[6/{total_steps}] ðŸ’¾ Saving Models...")
        step_start = datetime.now()
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        summary = {
            'training_date': start_time.isoformat(),
            'duration_seconds': duration,
            'gpu_available': self.gpu_available,
            'n_samples': len(df),
            'n_features': len(feature_names),
            'models': {
                name: {
                    'path': info['path'],
                    'train_time': info['train_time'],
                    'gpu_used': info.get('gpu_used', False)
                }
                for name, info in self.models.items()
            },
            'total_speedup': f"{sum(m['train_time'] for m in self.models.values()):.2f}s"
        }
        
        summary_path = self.output_dir / 'training_summary_gpu.json'
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"âœ… Completed in {(datetime.now()-step_start).total_seconds():.1f}s")
        
        print("\n" + "=" * 80)
        print("âœ… TRAINING COMPLETED")
        print("=" * 80)
        print(f"Total time:     {duration:.0f}s ({duration/60:.1f} min)")
        print(f"Models trained: {len(self.models)}")
        print(f"GPU used:       {'YES ðŸŽ®' if any(m.get('gpu_used') for m in self.models.values()) else 'NO ðŸ’»'}")
        print(f"Records:        {len(df):,}")
        print(f"Summary:        {summary_path}")
        print("=" * 80)
        
        return summary


def main():
    parser = argparse.ArgumentParser(description='Train ML models with GPU acceleration')
    parser.add_argument('--input', type=str, required=True,
                       help='Path to input data (CSV or Parquet)')
    parser.add_argument('--output', type=str, default='./ml/models',
                       help='Output directory for models')
    
    args = parser.parse_args()
    
    # Check if file exists
    if not Path(args.input).exists():
        logger.error(f"âŒ File not found: {args.input}")
        sys.exit(1)
    
    # Run training
    trainer = GPUModelTrainer(output_dir=args.output)
    trainer.run(args.input)


if __name__ == '__main__':
    main()
