# Arquitectura del Sistema de DetecciÃ³n de AnomalÃ­as Inmobiliarias

## Fecha: 28 de noviembre de 2025

## ğŸ“‹ Resumen Ejecutivo

Sistema profesional para detectar anomalÃ­as en transacciones inmobiliarias colombianas usando enfoque hÃ­brido: **ETL + EstadÃ­stica + Machine Learning + Dashboard**.

### Flujo General:
```
Datos Crudos (30.9M) 
  â†’ ETL Limpieza 
  â†’ Base de Datos SQL (5.7M limpios)
  â†’ 2 Caminos Paralelos:
     â”œâ”€ EstadÃ­stica: DetecciÃ³n reglas de negocio + Dashboard
     â””â”€ ML: Modelo anomalÃ­as avanzadas
```

---

## ğŸ—ï¸ Componentes del Sistema

### 1. ETL Pipeline (âœ… IMPLEMENTADO)

**Archivo**: `etl/clean_and_transform.py`

**Funciones**:
- âœ… ValidaciÃ³n y tipado de datos
- âœ… ClasificaciÃ³n de calidad (OK, ADVERTENCIA, ERROR)
- âœ… GeneraciÃ³n de mÃºltiples datasets:
  - `completo.parquet` - Todos tipados (30.9M)
  - `limpio.parquet` - Solo OK
  - `mercado.parquet` - DinÃ¡mica=1
  - `ml_training.parquet` - Listo para ML (5.7M)
  - `errores.parquet` - RevisiÃ³n manual
  - `advertencias.parquet` - RevisiÃ³n manual

**Reglas de Limpieza**:
```python
1. DinÃ¡mica_Inmobiliaria == '1' (solo mercado)
2. VALOR IS NOT NULL
3. VALOR numÃ©rico (no texto)
4. VALOR >= 1,000,000 COP (mÃ­n $250 USD)
5. VALOR <= 10,000,000,000 COP (mÃ¡x $2.5M USD)
6. YEAR_RADICA entre 2000-2025
7. DEPARTAMENTO y MUNICIPIO vÃ¡lidos
```

**Output**: `data/clean/` con 6 datasets + estadÃ­sticas

---

### 2. Base de Datos SQL (âœ… IMPLEMENTADO)

**Archivo**: `etl/export_to_database.py`

**Estructura**:

#### Tablas Principales:
1. **`transacciones`** - Datos completos (30.9M registros)
   - Todos los campos tipados correctamente
   - Columnas adicionales: `calidad_datos`, `tipo_error`, `es_mercado_valido`, `valor_valido`
   
2. **`stats_departamento_year`** - Agregados por departamento/aÃ±o
   - Campos: transacciones, valor_medio, valor_mediano, valor_std, valor_min, valor_max
   
3. **`stats_municipio_year`** - Agregados por municipio/aÃ±o (top 50)
   - Similar a departamento pero granularidad fina
   
4. **`transacciones_revision`** - Errores y advertencias
   - Para revisiÃ³n manual en dashboard
   - Campos: estado_revision, comentario_revision, revisado_por, fecha_revision

#### Vistas (para dashboard):
- `vista_resumen_departamento` - KPIs por departamento
- `vista_tendencia_anual` - Series temporales
- `vista_errores_tipo` - DistribuciÃ³n de errores
- `vista_pendientes_revision` - Cola de revisiÃ³n manual

#### Ãndices (optimizaciÃ³n):
- Por departamento + aÃ±o
- Por municipio + aÃ±o  
- Por valor
- Por calidad
- Por mercado vÃ¡lido

**Soporte**: PostgreSQL, SQL Server, SQLite

---

### 3. DetecciÃ³n EstadÃ­stica de Errores (ğŸ”„ PENDIENTE)

**Archivo**: `estadistica/detectar_errores_obvios.py` (a crear)

**Reglas de Negocio**:

```sql
-- Error 1: Valor muy bajo para tipo urbano
SELECT * FROM transacciones
WHERE tipo_predio_zona = 'URBANO' 
  AND municipio IN (top 10 ciudades)
  AND valor < 10_000_000  -- < $2,500 USD en BogotÃ¡ = ERROR

-- Error 2: Valor extremo vs mediana regional
SELECT * FROM transacciones t
JOIN stats_departamento_year s 
  ON t.departamento = s.departamento 
  AND t.year_radica = s.year
WHERE t.valor > s.valor_mediano * 50  -- 50x mediana = SOSPECHOSO

-- Error 3: Propiedad rural mÃ¡s cara que urbana
SELECT * FROM transacciones
WHERE tipo_predio_zona = 'RURAL'
  AND valor > (
    SELECT PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY valor)
    FROM transacciones
    WHERE tipo_predio_zona = 'URBANO' 
      AND departamento = t.departamento
  )

-- Error 4: TransacciÃ³n mÃºltiple sospechosa
SELECT matricula, COUNT(*) as veces, SUM(valor) as total
FROM transacciones
WHERE year_radica = CURRENT_YEAR
GROUP BY matricula
HAVING COUNT(*) > 10  -- mÃ¡s de 10 transacciones/aÃ±o = fraude posible

-- Error 5: Valor constante repetido (copiar-pegar)
SELECT valor, COUNT(*) as repeticiones,
       ARRAY_AGG(municipio) as municipios
FROM transacciones
WHERE valor IS NOT NULL
GROUP BY valor
HAVING COUNT(*) > 100 AND COUNT(DISTINCT municipio) > 10
```

**Output**: 
- Tabla `anomalias_estadisticas` con score de severidad
- CSV para revisiÃ³n: `errores_estadisticos_YYYY-MM-DD.csv`

---

### 4. Machine Learning - DetecciÃ³n Avanzada (ğŸ”„ PENDIENTE)

**Archivo**: `ml/train_anomaly_detector.py` (actualizar)

**Pipeline ML**:

#### Feature Engineering (20-25 features):
```python
FEATURES_CORE = [
    # Valor
    'valor',                    # Original
    'log_valor',                # Log-transform
    
    # GeogrÃ¡ficos
    'departamento_encoded',     # Label encoding (33 valores)
    'municipio_encoded',        # Label encoding top 100 + 'OTROS'
    'es_ciudad_grande',         # Top 10 municipios
    'es_departamento_top5',     # Top 5 departamentos
    
    # Temporales
    'year_radica',              # 2015-2023
    'aÃ±os_desde_2015',          # Normalizado
    
    # Tipo propiedad
    'es_urbano',                # Boolean
    'es_rural',                 # Boolean
    'es_ciudad_aglomeracion',   # CategorÃ­a ruralidad
    
    # TransacciÃ³n
    'predios_nuevos',           # 0/1
    'count_a',                  # Frecuencia transacciones
    'count_de',                 # Frecuencia
]

FEATURES_AGREGADOS = [
    # Ratios vs mercado local
    'valor_vs_mediana_dept_year',   # valor / mediana_departamento_aÃ±o
    'valor_vs_mediana_mun_year',    # valor / mediana_municipio_aÃ±o
    'zscore_valor_grupo',           # Z-score dentro grupo (dept+aÃ±o+tipo)
    
    # Contexto mercado
    'mediana_dept_year',            # Mediana del grupo
    'std_dept_year',                # Volatilidad del grupo
    'percentil_valor_dept',         # Percentil dentro grupo
]

TOTAL: ~20 features
```

#### Modelo HÃ­brido:
1. **Isolation Forest** (sklearn, CPU multi-core)
   - n_estimators=200
   - contamination=0.05 (esperamos 5% anomalÃ­as reales)
   - Fast screening: 25-30 min para 5.7M registros

2. **Autoencoder** (PyTorch, CPU/GPU)
   - Architecture: [20] â†’ 64 â†’ 32 â†’ 16 â†’ 32 â†’ 64 â†’ [20]
   - Entrena solo en datos "normales" (95%)
   - Detecta outliers por reconstruction error
   - Tiempo: 45-60 min CPU, 15-20 min GPU

3. **Ensemble**:
   - Confirmed: IF + AE ambos detectan (alta confianza)
   - Suspects: Solo uno detecta (media confianza)
   - Score final: weighted average

**Outputs**:
- `ml/models/isolation_forest.joblib`
- `ml/models/autoencoder.pth`
- `ml/models/feature_scaler.joblib`
- `ml/models/label_encoders.joblib`
- `data/results/anomalias_ml_YYYY-MM-DD.parquet` con scores

---

### 5. Dashboard & API (ğŸ”„ PENDIENTE)

**TecnologÃ­as**: FastAPI + React + Plotly

#### API Backend (`api/main.py`):

```python
@app.get("/api/stats/resumen")
def get_resumen_general():
    """KPIs generales del sistema"""
    return {
        "total_registros": 30_903_248,
        "registros_limpios": 5_702_742,
        "errores_detectados": 2_345_678,
        "anomalias_ml": 285_137,
        "pendientes_revision": 45_123
    }

@app.get("/api/stats/departamento/{nombre}")
def get_stats_departamento(nombre: str, year: int = None):
    """EstadÃ­sticas por departamento"""
    # Query a vista_resumen_departamento
    
@app.get("/api/anomalias/estadisticas")
def get_anomalias_estadisticas(
    tipo: str = None,
    severidad: str = None,
    limit: int = 100
):
    """AnomalÃ­as detectadas por reglas de negocio"""
    
@app.get("/api/anomalias/ml")
def get_anomalias_ml(
    score_min: float = 0.7,
    departamento: str = None,
    limit: int = 100
):
    """AnomalÃ­as detectadas por ML"""
    
@app.post("/api/revision/marcar")
def marcar_revision(pk: str, estado: str, comentario: str):
    """Marcar registro como revisado"""
    # UPDATE transacciones_revision
```

#### Frontend Dashboard:

**PÃ¡ginas**:
1. **Overview** - KPIs globales, grÃ¡ficos resumen
2. **ExploraciÃ³n** - Filtros por depto/mun/aÃ±o, tablas interactivas
3. **AnomalÃ­as EstadÃ­sticas** - Lista de errores obvios
4. **AnomalÃ­as ML** - Lista con scores, ordenable
5. **RevisiÃ³n Manual** - Interface para marcar/comentar registros
6. **Reportes** - Exportar CSV/Excel filtrados

**Visualizaciones**:
- Mapa coroplÃ©tico: anomalÃ­as por departamento
- Serie temporal: tendencia precios por regiÃ³n
- Box plots: distribuciÃ³n valores por tipo predio
- Scatter plot: valor vs mediana regional (outliers destacados)
- Tabla paginada: registros para revisiÃ³n

---

## ğŸ“Š Flujo de Datos Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATOS CRUDOS (30.9M)                      â”‚
â”‚                     datos.parquet                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ETL: clean_and_transform.py                     â”‚
â”‚  â€¢ Tipado correcto (VALOR float, YEAR int, etc.)           â”‚
â”‚  â€¢ ClasificaciÃ³n calidad (OK/ADVERTENCIA/ERROR)            â”‚
â”‚  â€¢ Filtros: DinÃ¡mica=1, Valor 1M-10B COP                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATASET COMPLETO    â”‚    â”‚   DATASET ML_TRAIN   â”‚
â”‚   (30.9M tipados)    â”‚    â”‚   (5.7M limpios)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                           â”‚
           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           BASE DE DATOS SQL (PostgreSQL)                    â”‚
â”‚  Tablas:                                                     â”‚
â”‚    â€¢ transacciones (30.9M)                                  â”‚
â”‚    â€¢ stats_departamento_year                                â”‚
â”‚    â€¢ stats_municipio_year                                   â”‚
â”‚    â€¢ transacciones_revision (errores + advertencias)        â”‚
â”‚  Vistas:                                                     â”‚
â”‚    â€¢ vista_resumen_departamento                             â”‚
â”‚    â€¢ vista_tendencia_anual                                  â”‚
â”‚    â€¢ vista_errores_tipo                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ESTADÃSTICA    â”‚         â”‚   MACHINE      â”‚
    â”‚  (Reglas SQL)   â”‚         â”‚   LEARNING     â”‚
    â”‚                 â”‚         â”‚  (IF + AE)     â”‚
    â”‚ â€¢ Valor vs      â”‚         â”‚                â”‚
    â”‚   mediana >50x  â”‚         â”‚ â€¢ 20 features  â”‚
    â”‚ â€¢ Urbano < 10M  â”‚         â”‚ â€¢ Ensemble     â”‚
    â”‚ â€¢ Rural > P95   â”‚         â”‚ â€¢ Scores 0-1   â”‚
    â”‚ â€¢ Frecuencia    â”‚         â”‚                â”‚
    â”‚   sospechosa    â”‚         â”‚                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                          â”‚
             â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚      â”‚
             â–¼      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TABLA: anomalias_detectadas                  â”‚
â”‚  Columnas:                                                   â”‚
â”‚    â€¢ pk, departamento, municipio, year, valor               â”‚
â”‚    â€¢ tipo_deteccion (ESTADISTICA / ML)                      â”‚
â”‚    â€¢ score_severidad (0-1)                                  â”‚
â”‚    â€¢ regla_violada / ml_score                               â”‚
â”‚    â€¢ estado_revision (PENDIENTE / REVISADO / CONFIRMADO)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API + DASHBOARD (FastAPI + React)               â”‚
â”‚  Endpoints:                                                  â”‚
â”‚    â€¢ GET /api/stats/resumen                                 â”‚
â”‚    â€¢ GET /api/anomalias/estadisticas                        â”‚
â”‚    â€¢ GET /api/anomalias/ml                                  â”‚
â”‚    â€¢ POST /api/revision/marcar                              â”‚
â”‚  UI:                                                         â”‚
â”‚    â€¢ Tablas interactivas con filtros                        â”‚
â”‚    â€¢ Visualizaciones (mapas, grÃ¡ficos)                      â”‚
â”‚    â€¢ Interface revisiÃ³n manual                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ PrÃ³ximos Pasos

### Fase 1: ETL + Base de Datos (âœ… Completado ~70%)
- [x] Pipeline ETL con clasificaciÃ³n calidad
- [x] Esquema SQL con tablas y vistas
- [ ] Ejecutar ETL en dataset completo
- [ ] Cargar a PostgreSQL
- [ ] Validar integridad datos en SQL

### Fase 2: DetecciÃ³n EstadÃ­stica (â³ Siguiente)
- [ ] Implementar 10 reglas de negocio clave
- [ ] Generar tabla `anomalias_estadisticas`
- [ ] Probar queries de detecciÃ³n
- [ ] Calcular tasas de falsos positivos

### Fase 3: Machine Learning (â³ Pendiente)
- [ ] Feature engineering completo (20 features)
- [ ] Entrenar Isolation Forest
- [ ] Entrenar Autoencoder
- [ ] Validar con datos conocidos
- [ ] Generar scores para 5.7M registros

### Fase 4: API + Dashboard (â³ Pendiente)
- [ ] API FastAPI con endpoints bÃ¡sicos
- [ ] Frontend React con pÃ¡ginas principales
- [ ] IntegraciÃ³n SQL queries
- [ ] Interface revisiÃ³n manual
- [ ] Deploy

---

## ğŸ“ˆ MÃ©tricas Esperadas

### ETL:
- **Input**: 30,903,248 registros
- **Output ML**: 5,702,742 registros limpios (18.5%)
- **Errores**: ~2.3M (7.5%)
- **Advertencias**: ~10.7M (34.6%)

### DetecciÃ³n EstadÃ­stica:
- **Errores obvios esperados**: ~500k (10% del limpio)
- **Ejemplos**:
  - Valor urbano < 1M en BogotÃ¡: ~50k
  - Valor > 50x mediana: ~10k
  - Frecuencia sospechosa: ~5k

### Machine Learning:
- **AnomalÃ­as ML esperadas**: ~285k (5% contamination)
- **Tiempo entrenamiento**: 90-120 min (CPU)
- **PrecisiÃ³n esperada**: 85-90%
- **Recall esperado**: 70-80%

### Dashboard:
- **Usuarios concurrentes**: 5-10
- **Queries/seg**: < 100ms (con Ã­ndices)
- **Revisiones/dÃ­a**: 100-500 registros

---

## ğŸ”§ Requisitos TÃ©cnicos

### Software:
- Python 3.10+
- PostgreSQL 14+ (o SQL Server 2019+)
- Node.js 18+ (para frontend)

### LibrerÃ­as Python:
```
pandas>=2.0
pyarrow>=12.0
sqlalchemy>=2.0
psycopg2>=2.9  # PostgreSQL
scikit-learn>=1.3
torch>=2.0
fastapi>=0.100
uvicorn>=0.23
```

### Hardware Recomendado:
- **ETL**: 16GB RAM, CPU 4+ cores
- **ML Training**: 16GB RAM, GPU opcional (acelera 3-4x)
- **Base de Datos**: 50GB disk, 8GB RAM
- **Dashboard**: 2GB RAM, CPU 2+ cores

---

## ğŸ“ Notas Finales

Este sistema implementa **3 capas de calidad**:

1. **ETL**: Limpieza bÃ¡sica, tipado, filtros rango
2. **EstadÃ­stica**: Reglas de negocio especÃ­ficas del dominio
3. **ML**: Patrones complejos no capturables con reglas

**Ventajas**:
- ETL elimina 80% de basura automÃ¡ticamente
- EstadÃ­stica detecta errores obvios rÃ¡pido (SQL queries)
- ML encuentra anomalÃ­as sutiles (valores razonables pero sospechosos)
- Dashboard permite revisiÃ³n manual expertos

**Resultado**: Sistema robusto, escalable, con mÃºltiples niveles de detecciÃ³n.
